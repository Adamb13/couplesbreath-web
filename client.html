<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>CouplesBreath – Monitor (WAV)</title>
<style>
  body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif; margin: 0; background:#0b1220; color:#e8eefc; }
  .wrap { max-width: 640px; margin: 24px auto; padding: 16px; }
  .card { background: #141c2f; border-radius: 16px; padding: 20px; box-shadow: 0 8px 24px rgba(0,0,0,.25); }
  button { padding: 12px 16px; border-radius: 10px; border: 0; font-weight: 600; cursor: pointer; }
  .start { background:#4ade80; color:#06210e; }
  .stop { background:#ef4444; color:#fff; margin-left: 8px; }
  .log { font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; white-space: pre-wrap; background:#0d1424; border-radius:12px; padding:12px; height: 160px; overflow:auto; margin-top: 12px; }
  .overlay {
    position: fixed; inset: 0; display:none; align-items:center; justify-content:center;
    background: rgba(8, 14, 28, .86); z-index: 9999;
  }
  .overlay .panel {
    background: #10192c; border: 2px solid #4ade80; color:#eafff0;
    border-radius: 20px; padding: 24px; text-align:center; width:min(90vw,480px);
    box-shadow: 0 12px 36px rgba(0,0,0,.5);
  }
  .muted { opacity: .7; }
</style>
</head>
<body>
<div class="wrap">
  <div class="card">
    <h2>CouplesBreath</h2>
    <p class="muted">Tap Start, allow the mic, talk normally, then raise intensity for a few seconds.</p>
    <div>
      <button id="btnStart" class="start">Start</button>
      <button id="btnStop" class="stop" disabled>Stop</button>
    </div>
    <div class="log" id="log"></div>
  </div>
</div>

<div class="overlay" id="overlay">
  <div class="panel">
    <h3>Let’s pause and breathe</h3>
    <p>Take 3 slow breaths together. In… out…</p>
    <button id="btnDismiss" class="start">Resume</button>
  </div>
</div>

<script>
const WS_URL = 'wss://pause-proxy.onrender.com/client';
const CHUNK_MS = 700; // keep well under Hume’s ~5s/message limit

const logEl = document.getElementById('log');
const overlay = document.getElementById('overlay');
const btnStart = document.getElementById('btnStart');
const btnStop = document.getElementById('btnStop');
const btnDismiss = document.getElementById('btnDismiss');

let ws = null;
let mediaStream = null;
let audioCtx, processor, micSource;
let wavBuffer = [];
let wavSampleRate = 48000;

function log(...args){ const line = args.map(a => typeof a === 'string' ? a : JSON.stringify(a)).join(' '); logEl.textContent += line + '\n'; logEl.scrollTop = logEl.scrollHeight; }
function b64FromUint8(u8){ let bin=''; for (let i=0;i<u8.length;i++) bin += String.fromCharCode(u8[i]); return btoa(bin); }
function speak(text){ try{ if (!window.speechSynthesis) return; const ut = new SpeechSynthesisUtterance(text); ut.rate = 0.9; window.speechSynthesis.cancel(); window.speechSynthesis.speak(ut);}catch{} }
function showOverlay(){ overlay.style.display = 'flex'; speak("Let's pause and take three slow breaths together."); }
function hideOverlay(){ overlay.style.display = 'none'; }

function floatTo16BitPCM(float32Array){
  const out = new Int16Array(float32Array.length);
  for (let i = 0; i < float32Array.length; i++){
    let s = Math.max(-1, Math.min(1, float32Array[i]));
    out[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
  }
  return out;
}

function makeWavBlobFromFrames(frames, sampleRate){
  // concat Int16 frames
  let totalSamples = 0;
  for (const f of frames) totalSamples += f.length;
  const pcm = new Int16Array(totalSamples);
  let offset = 0;
  for (const f of frames){ pcm.set(f, offset); offset += f.length; }

  // WAV header (PCM, mono)
  const blockAlign = 2; // 16-bit mono
  const byteRate = sampleRate * blockAlign;
  const dataSize = pcm.length * 2;
  const headerSize = 44;
  const buffer = new ArrayBuffer(headerSize + dataSize);
  const view = new DataView(buffer);

  writeStr(view, 0, 'RIFF');
  view.setUint32(4, 36 + dataSize, true);
  writeStr(view, 8, 'WAVE');
  writeStr(view, 12, 'fmt ');
  view.setUint32(16, 16, true);
  view.setUint16(20, 1, true);
  view.setUint16(22, 1, true);  // mono
  view.setUint32(24, sampleRate, true);
  view.setUint32(28, byteRate, true);
  view.setUint16(32, blockAlign, true);
  view.setUint16(34, 16, true);
  writeStr(view, 36, 'data');
  view.setUint32(40, dataSize, true);

  const out = new Uint8Array(buffer);
  out.set(new Uint8Array(pcm.buffer), 44);
  return new Blob([out], { type: 'audio/wav' });

  function writeStr(dv, offset, s){ for (let i=0;i<s.length;i++){ dv.setUint8(offset+i, s.charCodeAt(i)); } }
}

async function start(){
  btnStart.disabled = true; btnStop.disabled = false;
  log('starting…');

  ws = new WebSocket(WS_URL);
  ws.onopen = () => log('[web] ws open');
  ws.onclose = (e) => log('[web] ws close', e.code, e.reason || '');
  ws.onerror = (e) => log('[web] ws error', e.message || '');
  ws.onmessage = (ev) => {
    try {
      const msg = JSON.parse(ev.data);
      if (msg.type === 'trigger') { log('[trigger]', msg); showOverlay(); }
      else if (msg.type === 'hume') { log('[hume]', msg.status); }
      // optional: log risks
      // else if (msg.type === 'risk') { log('[risk]', msg.hyper, msg.hypo); }
    } catch {}
  };

  try {
    mediaStream = await navigator.mediaDevices.getUserMedia({ audio: { echoCancellation: true, noiseSuppression: true } });
  } catch (err) {
    log('mic error:', err.message || err);
    btnStart.disabled = false; btnStop.disabled = true;
    return;
  }

  // WAV path only (self-contained per chunk)
  audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 48000 });
  wavSampleRate = audioCtx.sampleRate;
  micSource = audioCtx.createMediaStreamSource(mediaStream);
  processor = audioCtx.createScriptProcessor(4096, 1, 1);
  let nextFlushAt = performance.now() + CHUNK_MS;

  processor.onaudioprocess = (e) => {
    const input = e.inputBuffer.getChannelData(0);
    wavBuffer.push(floatTo16BitPCM(input));

    const now = performance.now();
    if (now >= nextFlushAt) {
      nextFlushAt = now + CHUNK_MS;
      const wavBlob = makeWavBlobFromFrames(wavBuffer, wavSampleRate);
      wavBuffer = [];
      wavBlob.arrayBuffer().then(ab => {
        const b64 = b64FromUint8(new Uint8Array(ab));
        if (ws && ws.readyState === WebSocket.OPEN) {
          ws.send(JSON.stringify({ type: 'audio', data_b64: b64 }));
        }
      });
    }
  };

  micSource.connect(processor);
  processor.connect(audioCtx.destination);
  log('recording WAV chunks…');
}

function stop(){
  try { processor && processor.disconnect(); } catch{}
  try { micSource && micSource.disconnect(); } catch{}
  try { audioCtx && audioCtx.close(); } catch{}
  try { mediaStream && mediaStream.getTracks().forEach(t => t.stop()); } catch{}
  try { ws && ws.readyState === WebSocket.OPEN && ws.close(1000, 'done'); } catch{}
  btnStart.disabled = false; btnStop.disabled = true;
  log('stopped.');
}

btnStart.addEventListener('click', start);
btnStop.addEventListener('click', stop);
btnDismiss.addEventListener('click', () => overlay.style.display = 'none');
</script>
</body>
</html>
