<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no" />
<title>Couples Breath</title>
<style>
  body { font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; margin: 0; padding: 16px; }
  .btn { padding: 12px 16px; border-radius: 12px; border: none; background: #0d6efd; color: #fff; font-weight: 600; }
  .btn[disabled] { opacity: .5 }
  #overlay {
    display: none; position: fixed; inset: 0; z-index: 9999;
    background: rgba(0,0,0,.6);
    align-items: center; justify-content: center;
  }
  .card {
    background: #fff; padding: 24px; border-radius: 16px; width: min(90vw, 360px);
    text-align: center; box-shadow: 0 10px 30px rgba(0,0,0,.2);
  }
</style>
</head>
<body>

<h1 style="margin:0 0 8px">Couples Breath</h1>
<div id="status" style="margin:0 0 12px; color:#555">Idle</div>

<button id="startBtn" class="btn">Start discussion</button>
<button id="stopBtn" class="btn" style="margin-left: 8px; background:#6c757d" disabled>Stop</button>

<div style="margin-top:16px; font-size:14px; color:#333">hyper: <span id="hyper">0.00</span></div>

<!-- Pause overlay -->
<div id="overlay">
  <div class="card">
    <h2 style="margin:0 0 8px">Time to Pause</h2>
    <p style="margin:0 0 10px">Let’s take three slow breaths before continuing.</p>
    <div style="font-size:12px; opacity:.65">signal: <span data-score>0.00</span></div>
  </div>
</div>

<script>
const WS_URL = 'wss://pause-proxy.onrender.com/client';

let statusEl, hyperEl, overlayEl, scoreEl, startBtn, stopBtn;
let ws, mediaStream, audioCtx, processor, sourceNode;
let sending = false;

// ------------ audio helpers (16k mono PCM16 -> base64) ------------
function downsampleTo16k(input, inputSampleRate) {
  const ratio = inputSampleRate / 16000;
  const newLen = Math.round(input.length / ratio);
  const result = new Float32Array(newLen);
  let offset = 0;
  for (let i = 0; i < newLen; i++) {
    const start = Math.floor(i * ratio);
    const end   = Math.min(Math.floor((i + 1) * ratio), input.length);
    let sum = 0;
    for (let j = start; j < end; j++) sum += input[j];
    result[i] = sum / (end - start || 1);
  }
  return result;
}

function floatTo16BitPCM(float32Array) {
  const out = new Int16Array(float32Array.length);
  for (let i = 0; i < float32Array.length; i++) {
    let s = Math.max(-1, Math.min(1, float32Array[i]));
    out[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
  }
  return out;
}

function int16ToBase64(int16) {
  // Convert Int16Array -> Uint8Array -> base64
  const u8 = new Uint8Array(int16.buffer);
  let binary = '';
  for (let i = 0; i < u8.length; i++) binary += String.fromCharCode(u8[i]);
  return btoa(binary);
}

// ------------ WS + UI ------------
function connectWS() {
  ws = new WebSocket(WS_URL);
  ws.onopen = () => { statusEl.textContent = 'Connected. Tap Start to begin.'; };
  ws.onclose = () => { statusEl.textContent = 'Disconnected'; };
  ws.onerror = () => { statusEl.textContent = 'Connection error'; };

  ws.onmessage = (evt) => {
    let msg; try { msg = JSON.parse(evt.data); } catch { return; }

    if (msg.type === 'hume') {
      if (msg.status === 'connected') statusEl.textContent = 'Recording…';
      if (msg.status === 'closed')    statusEl.textContent = 'Closed';
      if (msg.status === 'error')     statusEl.textContent = 'Error: ' + (msg.message || '');
    }
    if (msg.type === 'risk') {
      if (typeof msg.hyper === 'number') {
        hyperEl.textContent = msg.hyper.toFixed(2);
      }
    }
    if (msg.type === 'trigger' && msg.kind === 'hyper') {
      showPauseOverlay(msg.score);
    }
  };
}

function showPauseOverlay(score) {
  overlayEl.style.display = 'flex';
  scoreEl.textContent = (score ?? 0).toFixed(2);
  try {
    const utter = new SpeechSynthesisUtterance("Let's pause and take three deep breaths together.");
    speechSynthesis.cancel();
    speechSynthesis.speak(utter);
  } catch {}
  setTimeout(() => overlayEl.style.display = 'none', 8000);
}

async function startStreaming() {
  if (sending) return;
  sending = true;
  startBtn.disabled = true;
  stopBtn.disabled = false;

  // mic
  mediaStream = await navigator.mediaDevices.getUserMedia({ audio: { echoCancellation: true, noiseSuppression: true }, video: false });
  audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 48000 });
  sourceNode = audioCtx.createMediaStreamSource(mediaStream);

  // ScriptProcessorNode (widely supported)
  const bufferSize = 4096;
  processor = audioCtx.createScriptProcessor(bufferSize, 1, 1);
  processor.onaudioprocess = (e) => {
    if (!ws || ws.readyState !== 1 || !sending) return;
    const input = e.inputBuffer.getChannelData(0);
    const ds = downsampleTo16k(input, audioCtx.sampleRate);
    const pcm16 = floatTo16BitPCM(ds);
    const b64 = int16ToBase64(pcm16);
    try { ws.send(JSON.stringify({ type: 'audio', data_b64: b64 })); } catch {}
  };

  sourceNode.connect(processor);
  processor.connect(audioCtx.destination); // required on iOS to “pull” audio graph
  statusEl.textContent = 'Recording…';
}

function stopStreaming() {
  sending = false;
  startBtn.disabled = false;
  stopBtn.disabled = true;

  try { if (processor) processor.disconnect(); } catch {}
  try { if (sourceNode) sourceNode.disconnect(); } catch {}
  try { if (audioCtx && audioCtx.state !== 'closed') audioCtx.close(); } catch {}
  try { if (mediaStream) mediaStream.getTracks().forEach(t => t.stop()); } catch {}

  statusEl.textContent = 'Stopped';
}

document.addEventListener('DOMContentLoaded', () => {
  statusEl  = document.getElementById('status');
  hyperEl   = document.getElementById('hyper');
  overlayEl = document.getElementById('overlay');
  scoreEl   = overlayEl.querySelector('[data-score]');
  startBtn  = document.getElementById('startBtn');
  stopBtn   = document.getElementById('stopBtn');

  connectWS();

  startBtn.addEventListener('click', startStreaming);
  stopBtn.addEventListener('click', stopStreaming);
});
</script>
</body>
</html>
