<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Couples Breath</title>
  <style>
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; margin:0; padding:24px; background:#0b1220; color:#e7eefc; }
    h1 { margin:0 0 8px 0; font-size:22px; }
    .card { background:#121a2b; border:1px solid #253552; border-radius:16px; padding:16px; max-width:720px; }
    .row { display:flex; gap:12px; align-items:center; flex-wrap:wrap; }
    button { background:#2b66f6; color:white; border:none; border-radius:12px; padding:10px 16px; font-size:16px; }
    button.secondary { background:#1c2740; }
    .pill { background:#18243a; border:1px solid #2a3b5d; padding:6px 10px; border-radius:999px; font-size:13px; }
    .big { font-size:40px; font-weight:700; margin:6px 0 0 0; line-height:1.1; }
    .muted { color:#a8b3c9; font-size:13px; }
    .debug { font-family: ui-monospace, SFMono-Regular, Menlo, monospace; font-size:12px; white-space:pre-wrap; background:#0d1526; border:1px dashed #334d7a; border-radius:12px; padding:10px; margin-top:10px; max-height:180px; overflow:auto; }
    .overlay {
      position: fixed; inset:0; display:none; place-items:center; backdrop-filter: blur(2px);
      background: rgba(11,18,32,0.65); z-index: 9999;
    }
    .overlay.show { display:grid; }
    .overlay .panel {
      background: #ffd9d9; color:#7a0e0e; border-radius:20px; padding:22px 20px; width:min(92vw,520px);
      text-align:center; box-shadow: 0 12px 28px rgba(0,0,0,0.35);
    }
    .overlay .title { font-size:28px; font-weight:800; margin:0 0 8px 0; }
    .overlay .body { font-size:16px; color:#5a0c0c; }
  </style>
</head>
<body>
  <div class="card">
    <div class="row" style="justify-content:space-between;">
      <h1>Couples Breath</h1>
      <div class="pill">status: <span id="status">idle</span></div>
    </div>

    <div class="big">hyper: <span id="hyper">-</span></div>
    <div class="muted" id="mode">mode: -</div>

    <div class="row" style="margin-top:14px;">
      <button id="startBtn">Start session</button>
      <button id="stopBtn" class="secondary" disabled>Stop</button>
    </div>

    <div class="debug" id="log"></div>
  </div>

  <!-- PAUSE overlay -->
  <div class="overlay" id="pauseOverlay">
    <div class="panel">
      <div class="title">PAUSE and breathe</div>
      <div class="body">Both of you: inhale 4 · hold 4 · exhale 6. Try 3 rounds.</div>
    </div>
  </div>

<script>
(() => {
  const statusEl = document.getElementById('status');
  const hyperEl  = document.getElementById('hyper');
  const logEl    = document.getElementById('log');
  const modeEl   = document.getElementById('mode');
  const overlay  = document.getElementById('pauseOverlay');
  const startBtn = document.getElementById('startBtn');
  const stopBtn  = document.getElementById('stopBtn');

  // Always use WSS when page is HTTPS
  const wsScheme = (location.protocol === 'https:') ? 'wss' : 'ws';
  const PROXY_WS = `${wsScheme}://pause-proxy.onrender.com/client`;

  let ws, ctx, micStream, source, processor;
  let running = false;
  let speakReady = false;

  function log(s) {
    const t = new Date().toLocaleTimeString();
    logEl.textContent = `[${t}] ${s}\n` + logEl.textContent;
  }

  // Simple TTS with safety guard
  function say(text) {
    try {
      const u = new SpeechSynthesisUtterance(text);
      u.rate = 0.95; u.pitch = 1.0;
      speechSynthesis.cancel();
      speechSynthesis.speak(u);
    } catch {}
  }

  // Downsample Float32 PCM to 16k, return Int16Array
  function downsampleTo16k(float32, fromSampleRate) {
    const toRate = 16000;
    if (fromSampleRate === toRate) {
      // convert to int16 directly
      const out = new Int16Array(float32.length);
      for (let i=0;i<float32.length;i++){
        let s = Math.max(-1, Math.min(1, float32[i]));
        out[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
      }
      return out;
    }
    const ratio = fromSampleRate / toRate;
    const newLen = Math.round(float32.length / ratio);
    const out = new Int16Array(newLen);
    let o = 0;
    let i = 0;
    while (o < newLen) {
      const nextI = Math.min(float32.length, Math.round((o+1)*ratio));
      // simple average (box) resample
      let sum = 0, count = 0;
      while (i < nextI) { sum += float32[i++]; count++; }
      const avg = count ? (sum / count) : 0;
      const s = Math.max(-1, Math.min(1, avg));
      out[o++] = s < 0 ? s * 0x8000 : s * 0x7FFF;
    }
    return out;
  }

  // Build a WAV buffer (16-bit PCM, mono, 16kHz)
  function int16ToWav(int16, sampleRate = 16000) {
    const numFrames = int16.length;
    const bytesPerSample = 2;
    const blockAlign = 1 * bytesPerSample;
    const byteRate = sampleRate * blockAlign;

    const headerSize = 44;
    const dataSize = numFrames * bytesPerSample;
    const buf = new ArrayBuffer(headerSize + dataSize);
    const view = new DataView(buf);

    // "RIFF"
    writeStr(view, 0, 'RIFF');
    view.setUint32(4, 36 + dataSize, true);
    writeStr(view, 8, 'WAVE');

    // fmt  chunk
    writeStr(view, 12, 'fmt ');
    view.setUint32(16, 16, true);            // PCM chunk size
    view.setUint16(20, 1, true);             // audio format = PCM
    view.setUint16(22, 1, true);             // channels = 1
    view.setUint32(24, sampleRate, true);    // sample rate
    view.setUint32(28, byteRate, true);      // byte rate
    view.setUint16(32, blockAlign, true);    // block align
    view.setUint16(34, 16, true);            // bits per sample

    // data chunk
    writeStr(view, 36, 'data');
    view.setUint32(40, dataSize, true);

    // PCM samples
    let off = 44;
    for (let i=0;i<numFrames;i++, off+=2) view.setInt16(off, int16[i], true);

    return new Uint8Array(buf);
  }

  function writeStr(view, offset, str) {
    for (let i=0;i<str.length;i++) view.setUint8(offset+i, str.charCodeAt(i));
  }

  function toBase64(uint8) {
    let binary = '';
    for (let i=0;i<uint8.length;i++) binary += String.fromCharCode(uint8[i]);
    return btoa(binary);
  }

  function showOverlay() { overlay.classList.add('show'); }
  function hideOverlay() { overlay.classList.remove('show'); }

  function connectWS() {
    ws = new WebSocket(PROXY_WS);
    ws.onopen = () => { statusEl.textContent = 'connected'; log('ws open'); };
    ws.onclose = (e) => { statusEl.textContent = 'closed'; log(`ws close ${e.code||''}`); stopCapture(); };
    ws.onerror = (e) => { log('ws error'); };

    ws.onmessage = (ev) => {
      let msg; try { msg = JSON.parse(ev.data); } catch { return; }
      if (msg.type === 'hello') {
        modeEl.textContent = `mode: ${msg.mode}`;
      } else if (msg.type === 'risk') {
        hyperEl.textContent = msg.hyper?.toFixed ? msg.hyper.toFixed(2) : String(msg.hyper);
      } else if (msg.type === 'trigger' && msg.kind === 'hyper') {
        showOverlay();
        if (speakReady) say('Pause and breathe. Inhale 4, hold 4, exhale 6. Try three rounds.');
        setTimeout(hideOverlay, 9000);
      } else if (msg.type === 'hume' && msg.status) {
        statusEl.textContent = msg.status;
      }
    };
  }

  async function startCapture() {
    if (running) return;
    running = true; speakReady = true;
    log('requesting mic…');
    const stream = await navigator.mediaDevices.getUserMedia({
      audio: {
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true
      }
    });
    micStream = stream;
    ctx = new (window.AudioContext || window.webkitAudioContext)({ latencyHint: 'interactive' });
    source = ctx.createMediaStreamSource(stream);

    // Use ScriptProcessor to build ~1s chunks we’ll downsample to 16k and wrap as WAV
    const BUFFER_MS = 1000;
    const framesPerBuffer = Math.round(ctx.sampleRate * BUFFER_MS / 1000);
    processor = ctx.createScriptProcessor( Math.min(16384, Math.pow(2, Math.ceil(Math.log2(framesPerBuffer)))) , 1, 1);

    let floatBuffer = new Float32Array(0);

    processor.onaudioprocess = (e) => {
      if (!running) return;
      const input = e.inputBuffer.getChannelData(0);
      // append
      const tmp = new Float32Array(floatBuffer.length + input.length);
      tmp.set(floatBuffer, 0); tmp.set(input, floatBuffer.length);
      floatBuffer = tmp;

      // when we have ~1s of audio, encode & send
      if (floatBuffer.length >= framesPerBuffer) {
        const int16 = downsampleTo16k(floatBuffer, ctx.sampleRate); // Int16Array mono 16k
        const wav = int16ToWav(int16, 16000);                       // Uint8Array WAV
        const b64 = toBase64(wav);
        if (ws && ws.readyState === 1) {
          ws.send(JSON.stringify({ type: 'audio', data_b64: b64 }));
          log(`sent wav ${wav.length} bytes`);
        }
        floatBuffer = new Float32Array(0);
      }
    };

    source.connect(processor);
    processor.connect(ctx.destination); // required on iOS to keep processor running

    statusEl.textContent = 'recording…';
  }

  function stopCapture() {
    running = false;
    try { processor && processor.disconnect(); } catch {}
    try { source && source.disconnect(); } catch {}
    try { micStream && micStream.getTracks().forEach(t => t.stop()); } catch {}
    try { ctx && ctx.close(); } catch {}
    processor = null; source = null; micStream = null; ctx = null;
  }

  startBtn.onclick = async () => {
    startBtn.disabled = true; stopBtn.disabled = false;
    hideOverlay();
    if (!ws || ws.readyState > 1) connectWS();
    // give WS a tick to open
    setTimeout(() => startCapture().catch(err => { log('mic error: '+err.message); }), 200);
  };
  stopBtn.onclick = () => {
    stopBtn.disabled = true; startBtn.disabled = false;
    stopCapture();
    try { ws && ws.close(); } catch {}
  };

  // iOS: start audio context on first touch
  document.body.addEventListener('touchstart', () => {
    if (ctx && ctx.state === 'suspended') ctx.resume();
  }, {passive:true});
})();
</script>
</body>
</html>
